{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a9f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System] Current Date: 2026-01-11\n",
      "[Debug] DB Market Date: 2026-01-11\n",
      "[Cache] Today's market snapshot found. Loading...\n",
      "[Debug] DB Full Analysis Date: 2026-01-11\n",
      "[Cache] Today's deep analysis found. Loading directly...\n",
      "[Init] Market Filter: Excluded 359 STAR Market (ç§‘åˆ›æ¿) stocks.\n",
      "[Analysis] Calculating Normalized Scores (Balanced Strategy)...\n",
      "\n",
      "============================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ›‘ é£é™©è¯„ä¼°æŠ¥å‘Š (åŸºäºå‡å€¼å›å½’ç†è®º)\n",
      "================================================================================\n",
      "ä»£ç        åç§°       ç°ä»·       ä¹–ç¦»ç‡(%)     MA60æˆæœ¬     æ“ä½œå»ºè®®\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataEngine' object has no attribute 'fetch_historical_kline'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 416\u001b[39m\n\u001b[32m    413\u001b[39m price = row[\u001b[33m'\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# è®¡ç®—é£é™©\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m status, bias, _, ma60 = \u001b[43mrisk_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43massess_risk\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# æ ¼å¼åŒ–è¾“å‡º\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbias\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<10.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mma60\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<10.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 301\u001b[39m, in \u001b[36mRiskManager.assess_risk\u001b[39m\u001b[34m(self, symbol, current_price)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    298\u001b[39m \u001b[33;03mè¯„ä¼°å½“å‰ä»·æ ¼çš„é£é™©ç­‰çº§\u001b[39;00m\n\u001b[32m    299\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    300\u001b[39m \u001b[38;5;66;03m# è·å–è¿‡å» 90 å¤©æ•°æ®ä»¥è®¡ç®— MA60\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m df = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdaq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_historical_kline\u001b[49m(symbol, period=\u001b[33m'\u001b[39m\u001b[33mdaily\u001b[39m\u001b[33m'\u001b[39m, start_date=\u001b[33m'\u001b[39m\u001b[33m20251001\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df.empty \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df) < \u001b[32m60\u001b[39m:\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mUnknown (No Data)\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataEngine' object has no attribute 'fetch_historical_kline'"
     ]
    }
   ],
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "# [StorageEngine ä¿æŒä¸å˜ï¼Œæ— éœ€ä¿®æ”¹]\n",
    "class StorageEngine:\n",
    "    def __init__(self, db_path='data/stock_market.db'):\n",
    "        os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "\n",
    "    def save_to_sql(self, df, table_name, if_exists='replace'):\n",
    "        try:\n",
    "            df.to_sql(table_name, self.conn, if_exists=if_exists, index=False)\n",
    "            print(f\"[Storage] Table '{table_name}' saved. Rows: {len(df)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Storage] Error saving {table_name}: {e}\")\n",
    "\n",
    "    def load_from_sql(self, table_name):\n",
    "        try:\n",
    "            return pd.read_sql(f\"SELECT * FROM {table_name}\", self.conn)\n",
    "        except Exception as e:\n",
    "            # print(f\"[Storage] Table {table_name} not found.\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def table_exists(self, table_name):\n",
    "        self.cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'\")\n",
    "        return self.cursor.fetchone() is not None\n",
    "    \n",
    "    def get_latest_date(self, table_name, date_column='fetch_date'):\n",
    "            \"\"\"è·å–è¡¨ä¸­æœ€æ–°çš„è®°å½•æ—¥æœŸ\"\"\"\n",
    "            if not self.table_exists(table_name):\n",
    "                return None\n",
    "            try:\n",
    "                self.cursor.execute(f\"SELECT MAX({date_column}) FROM {table_name}\")\n",
    "                return self.cursor.fetchone()[0]\n",
    "            except:\n",
    "                return None\n",
    "    def close(self):\n",
    "        self.conn.close()\n",
    "\n",
    "class DataEngine:\n",
    "    def __init__(self):\n",
    "        self.request_interval = 0.5 \n",
    "\n",
    "    def fetch_market_snapshot(self):\n",
    "        # ... (è¿™éƒ¨åˆ†ä¿æŒä¸å˜) ...\n",
    "        print(\"[DAQ] Fetching Real-time Market Snapshot...\")\n",
    "        df_spot = ak.stock_zh_a_spot_em()\n",
    "        rename_map = {\n",
    "            'ä»£ç ': 'symbol', 'åç§°': 'name', \n",
    "            'æœ€æ–°ä»·': 'price', 'æ¶¨è·Œå¹…': 'change_pct',\n",
    "            'å¸‚ç›ˆç‡-åŠ¨æ€': 'pe_ttm', 'å¸‚å‡€ç‡': 'pb', \n",
    "            'æ€»å¸‚å€¼': 'market_cap', 'æ¢æ‰‹ç‡': 'turnover'\n",
    "        }\n",
    "        df_spot = df_spot.rename(columns=rename_map)\n",
    "        numeric_cols = ['pe_ttm', 'pb', 'market_cap', 'change_pct']\n",
    "        for col in numeric_cols:\n",
    "            if col in df_spot.columns:\n",
    "                df_spot[col] = pd.to_numeric(df_spot[col], errors='coerce')\n",
    "        return df_spot\n",
    "\n",
    "    def fetch_detailed_financials(self, symbol_list):\n",
    "        print(f\"[DAQ] Starting Deep Reconstruction for {len(symbol_list)} stocks...\")\n",
    "        financial_data = []\n",
    "        \n",
    "        for symbol in tqdm(symbol_list):\n",
    "            try:\n",
    "                df = None\n",
    "                source = 'em'\n",
    "                \n",
    "                # 1. å°è¯• EM\n",
    "                try:\n",
    "                    df = ak.stock_financial_analysis_indicator(symbol=symbol)\n",
    "                    if df is None or df.empty: raise ValueError\n",
    "                except:\n",
    "                    # 2. å°è¯• THS\n",
    "                    try:\n",
    "                        source = 'ths'\n",
    "                        df = ak.stock_financial_abstract_ths(symbol=symbol, indicator=\"æŒ‰æŠ¥å‘ŠæœŸ\")\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "                if df is None or df.empty: continue\n",
    "\n",
    "                # ==========================================================\n",
    "                # å…³é”®ä¿®æ­£ 1: å¼ºåˆ¶æ—¶é—´æ’åº (Time Ordering)\n",
    "                # ==========================================================\n",
    "                # æ— è®ºå“ªä¸ªæ¥å£ï¼Œå…ˆæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œè½¬ä¸º datetime å¹¶é™åºæ’åˆ—\n",
    "                date_col = None\n",
    "                for col in df.columns:\n",
    "                    if 'æ—¥æœŸ' in str(col) or 'æŠ¥å‘ŠæœŸ' in str(col):\n",
    "                        date_col = col\n",
    "                        break\n",
    "                \n",
    "                if date_col:\n",
    "                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "                    df = df.sort_values(by=date_col, ascending=False) # é™åºï¼šæœ€æ–°çš„åœ¨æœ€ä¸Šé¢\n",
    "                \n",
    "                # å–æœ€æ–°çš„ä¸€è¡Œ (Now this is truly the latest data)\n",
    "                latest = df.iloc[0]\n",
    "\n",
    "                # ==========================================================\n",
    "                # å…³é”®ä¿®æ­£ 2: è¶…å¼ºé²æ£’çš„å–å€¼å‡½æ•° (Handle Boolean)\n",
    "                # ==========================================================\n",
    "                def get_fuzzy(keywords_list):\n",
    "                    for col_name in latest.index:\n",
    "                        if any(k in str(col_name) for k in keywords_list):\n",
    "                            raw_val = latest[col_name]\n",
    "                            \n",
    "                            # å¤„ç†å¸ƒå°”å€¼ False/True\n",
    "                            if isinstance(raw_val, bool):\n",
    "                                return 0.0\n",
    "                                \n",
    "                            # å¤„ç†å­—ç¬¦ä¸²æ¸…æ´—\n",
    "                            val_str = str(raw_val).replace('%', '').replace(',', '').replace('ä¸‡', '').replace('äº¿', '')\n",
    "                            try:\n",
    "                                return float(val_str)\n",
    "                            except:\n",
    "                                return 0.0\n",
    "                    return 0.0\n",
    "\n",
    "                data_point = {'symbol': symbol}\n",
    "                data_point['roe'] = get_fuzzy(['å‡€èµ„äº§æ”¶ç›Šç‡', 'ROE'])\n",
    "                data_point['gross_margin'] = get_fuzzy(['æ¯›åˆ©ç‡', 'é”€å”®æ¯›åˆ©'])\n",
    "                data_point['net_profit_growth'] = get_fuzzy(['å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿', 'å‡€åˆ©æ¶¦å¢é•¿', 'å½’å±å‡€åˆ©æ¶¦åŒæ¯”'])\n",
    "                data_point['debt_ratio'] = get_fuzzy(['èµ„äº§è´Ÿå€ºç‡', 'è´Ÿå€ºåˆè®¡'])\n",
    "                data_point['eps'] = get_fuzzy(['åŸºæœ¬æ¯è‚¡æ”¶ç›Š', 'æ¯è‚¡æ”¶ç›Š'])\n",
    "                data_point['ocf_per_share'] = get_fuzzy(['æ¯è‚¡ç»è¥æ´»åŠ¨', 'æ¯è‚¡ç»è¥ç°é‡‘', 'ç»è¥å‡€ç°é‡‘æµ/è‚¡'])\n",
    "                \n",
    "                eps = data_point['eps']\n",
    "                data_point['cash_to_profit_ratio'] = (data_point['ocf_per_share'] / eps) if eps != 0 else 0\n",
    "                \n",
    "                financial_data.append(data_point)\n",
    "                time.sleep(0.3 if source == 'em' else 0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                # print(f\"[Error] {symbol}: {e}\")\n",
    "                continue\n",
    "                    \n",
    "        return pd.DataFrame(financial_data)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class StrategyEngine:\n",
    "    def __init__(self, data, exclude_star=True):\n",
    "        \"\"\"\n",
    "        :param exclude_star: æ˜¯å¦å‰”é™¤ç§‘åˆ›æ¿ (ä»£ç  688 å¼€å¤´)ï¼Œé»˜è®¤ä¸º True\n",
    "        \"\"\"\n",
    "        # 1. å¡«å……ç©ºå€¼\n",
    "        self.data = data.fillna(0)\n",
    "        \n",
    "        # 2. å¸‚åœºå‡†å…¥è¿‡æ»¤ (Market Segment Veto)\n",
    "        if exclude_star:\n",
    "            # ç¡®ä¿ symbol æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¹¶å‰”é™¤ 688 30 å¼€å¤´çš„æ ‡çš„\n",
    "         \n",
    "            initial_count = len(self.data)\n",
    "            self.data = self.data[~self.data['symbol'].astype(str).str.startswith('688')]\n",
    "            self.data = self.data[~self.data['symbol'].astype(str).str.startswith('30')]\n",
    "            removed_count = initial_count - len(self.data)\n",
    "            print(f\"[Init] Market Filter: Excluded {removed_count} STAR Market (ç§‘åˆ›æ¿) stocks.\")\n",
    "\n",
    "    def _normalize(self, series, ascending=True):\n",
    "        \"\"\"\n",
    "        [Helper] å½’ä¸€åŒ–å‡½æ•°ï¼šå°†æ•°æ®æ˜ å°„åˆ° 0 - 100 åˆ†\n",
    "        :param ascending: True è¡¨ç¤ºå€¼è¶Šå¤§åˆ†è¶Šé«˜ (å¦‚ ROE)ï¼ŒFalse è¡¨ç¤ºå€¼è¶Šå°åˆ†è¶Šé«˜ (å¦‚ PE)\n",
    "        \"\"\"\n",
    "        # 1. Winsorization (å»æå€¼): å°†è¶…è¿‡ 95% å’Œä½äº 5% çš„å¼‚å¸¸å€¼åˆ‡æ‰\n",
    "        # è¿™å°±åƒåœ¨ç‰©ç†å®éªŒä¸­å‰”é™¤ 3-sigma ä¹‹å¤–çš„å™ªå£°\n",
    "        upper = series.quantile(0.95)\n",
    "        lower = series.quantile(0.05)\n",
    "        series_clipped = series.clip(lower, upper)\n",
    "\n",
    "        # 2. Min-Max Scaling\n",
    "        if ascending:\n",
    "            score = (series_clipped - lower) / (upper - lower) * 100\n",
    "        else:\n",
    "            # å¯¹äº PE è¿™ç§æŒ‡æ ‡ï¼Œè¶Šä½è¶Šå¥½ï¼Œæ‰€ä»¥åå‘æ˜ å°„\n",
    "            score = (upper - series_clipped) / (upper - lower) * 100\n",
    "            \n",
    "        return score.fillna(0) # é˜²æ­¢é™¤ä»¥é›¶äº§ç”Ÿçš„ NaN\n",
    "\n",
    "    def apply_ranking(self, top_n=10):\n",
    "        \"\"\"\n",
    "        ç­–ç•¥ 1: å‡è¡¡æ‰“åˆ†æ¨¡å‹ (Balanced Scoring)\n",
    "        ä½¿ç”¨äº†å½’ä¸€åŒ–ç®—æ³•ï¼Œè§£å†³äº†æŒ‡æ ‡é‡çº²ä¸ä¸€è‡´çš„é—®é¢˜\n",
    "        \"\"\"\n",
    "        print(\"[Analysis] Calculating Normalized Scores (Balanced Strategy)...\")\n",
    "        df = self.data.copy()\n",
    "\n",
    "        # 1. åŸºç¡€è¿‡æ»¤ (Veto Cuts)\n",
    "        # å‰”é™¤äºæŸ (PE<0)ã€å‰”é™¤æç«¯æ³¡æ²« (PE>80)ã€å‰”é™¤å¾®ç›˜è‚¡ (å¸‚å€¼<20äº¿)\n",
    "        mask = (df['pe_ttm'] > 0) & (df['pe_ttm'] < 80) & (df['market_cap'] > 20_0000_0000)\n",
    "        df = df[mask].copy()\n",
    "\n",
    "        if df.empty: return pd.DataFrame()\n",
    "\n",
    "        # 2. è®¡ç®—å„åˆ†é¡¹å¾—åˆ† (0-100åˆ†)\n",
    "        # PE: è¶Šä½åˆ†è¶Šé«˜\n",
    "        df['score_val'] = self._normalize(df['pe_ttm'], ascending=False)\n",
    "        # ROE: è¶Šé«˜åˆ†è¶Šé«˜\n",
    "        df['score_roe'] = self._normalize(df['roe'], ascending=True)\n",
    "        # å¢é•¿ç‡: è¶Šé«˜åˆ†è¶Šé«˜\n",
    "        df['score_growth'] = self._normalize(df['net_profit_growth'], ascending=True)\n",
    "        # ç°é‡‘æµè´¨é‡: è¶Šé«˜åˆ†è¶Šé«˜ (æ–°å¢)\n",
    "        df['score_cash'] = self._normalize(df['cash_to_profit_ratio'], ascending=True)\n",
    "\n",
    "        # 3. åŠ æƒæ€»åˆ† (Total Score)\n",
    "        # æƒé‡åˆ†é…ï¼šç›ˆåˆ©(40%) + æˆé•¿(30%) + ä¼°å€¼(20%) + ç°é‡‘æµ(10%)\n",
    "        df['total_score'] = (\n",
    "            df['score_roe'] * 0.4 +\n",
    "            df['score_growth'] * 0.3 +\n",
    "            df['score_val'] * 0.2 +\n",
    "            df['score_cash'] * 0.1\n",
    "        )\n",
    "\n",
    "        return df.sort_values(by='total_score', ascending=False).head(top_n)\n",
    "\n",
    "    # =================================================================\n",
    "    #  æ–°å¢ç­–ç•¥åº“\n",
    "    # =================================================================\n",
    "\n",
    "    def select_garp(self, top_n=10):\n",
    "        \"\"\"\n",
    "        ç­–ç•¥ 2: GARP ç­–ç•¥ (Growth at a Reasonable Price)\n",
    "        æ ¸å¿ƒé€»è¾‘ï¼šå¯»æ‰¾ PEG < 1 çš„è‚¡ç¥¨ (å¢é•¿é€Ÿåº¦ > ä¼°å€¼å€æ•°)\n",
    "        \"\"\"\n",
    "        print(\"[Analysis] Applying GARP Strategy (PEG < 1)...\")\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # è®¡ç®— PEG\n",
    "        # æ³¨æ„ï¼šé¿å…é™¤ä»¥ 0 æˆ–è´Ÿå¢é•¿\n",
    "        mask = (df['pe_ttm'] > 0) & (df['net_profit_growth'] > 0)\n",
    "        df = df[mask].copy()\n",
    "        \n",
    "        df['peg'] = df['pe_ttm'] / df['net_profit_growth']\n",
    "        \n",
    "        # ç­›é€‰æ¡ä»¶\n",
    "        cuts = (\n",
    "            (df['peg'] < 1.0) &               # è¢«ä½ä¼°\n",
    "            (df['peg'] > 0.1) &               # æ’é™¤å¼‚å¸¸æ•°æ®\n",
    "            (df['roe'] > 12) &                # å¿…é¡»æœ‰åŸºæœ¬ç›ˆåˆ©èƒ½åŠ›\n",
    "            (df['net_profit_growth'] > 15)    # çœŸæ­£çš„æˆé•¿è‚¡\n",
    "        )\n",
    "        \n",
    "        result = df[cuts].sort_values(by='peg', ascending=True) # PEG è¶Šå°è¶Šå¥½\n",
    "        return result.head(top_n)\n",
    "\n",
    "    def select_high_quality(self, top_n=10):\n",
    "        \"\"\"\n",
    "        ç­–ç•¥ 3: â€œåªä¹°å¥½å…¬å¸â€ (High Quality / Buffett Style)\n",
    "        æ ¸å¿ƒé€»è¾‘ï¼šä¸çœ‹è‚¡ä»·å¤šè´µï¼Œåªçœ‹å…¬å¸æœ‰å¤šå¥½ (é«˜æ¯›åˆ©ã€é«˜ROEã€ä½è´Ÿå€º)\n",
    "        \"\"\"\n",
    "        print(\"[Analysis] Applying High Quality Strategy (Moat)...\")\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        cuts = (\n",
    "            (df['roe'] > 20) &                # æå…¶ä¼˜ç§€çš„ç›ˆåˆ©èƒ½åŠ›\n",
    "            (df['gross_margin'] > 40) &       # æé«˜çš„æ¯›åˆ© (æŠ¤åŸæ²³)\n",
    "            (df['debt_ratio'] < 50) &         # ä½æ æ†é£é™©\n",
    "            (df['cash_to_profit_ratio'] > 0.8)# èµšçš„æ˜¯çœŸé’±\n",
    "        )\n",
    "        \n",
    "        # æ—¢ç„¶æ˜¯å¥½å…¬å¸ï¼ŒæŒ‰ ROE æ’åºï¼Œé€‰æœ€èµšé’±çš„\n",
    "        result = df[cuts].sort_values(by='roe', ascending=False)\n",
    "        return result.head(top_n)\n",
    "\n",
    "    def select_deep_value(self, top_n=10):\n",
    "        \"\"\"\n",
    "        ç­–ç•¥ 4: æ·±åº¦ä»·å€¼ / çƒŸè’‚è‚¡ (Deep Value)\n",
    "        æ ¸å¿ƒé€»è¾‘ï¼šä»·æ ¼è·Œæ— å¯è·Œï¼Œç ´å‡€ï¼Œä½†ä¾ç„¶ç›ˆåˆ©\n",
    "        \"\"\"\n",
    "        print(\"[Analysis] Applying Deep Value Strategy (Cigar Butt)...\")\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        cuts = (\n",
    "            (df['pe_ttm'] > 0) & (df['pe_ttm'] < 15) &  # ä½ PE\n",
    "            (df['pb'] > 0) & (df['pb'] < 1.5) &         # ä½ PB (ç ´å‡€è¾¹ç¼˜)\n",
    "            (df['roe'] > 8)                             # è¿˜åœ¨èµšé’±ï¼Œä¸æ˜¯åƒåœ¾è‚¡\n",
    "        )\n",
    "        \n",
    "        # æŒ‰ PB æ’åºï¼Œè¶Šä¾¿å®œè¶Šå¥½\n",
    "        result = df[cuts].sort_values(by='pb', ascending=True)\n",
    "        return result.head(top_n)\n",
    "\n",
    "\n",
    "class RiskManager:\n",
    "    def __init__(self, daq_engine):\n",
    "        self.daq = daq_engine\n",
    "\n",
    "    def assess_risk(self, symbol, current_price):\n",
    "        \"\"\"\n",
    "        è¯„ä¼°å½“å‰ä»·æ ¼çš„é£é™©ç­‰çº§\n",
    "        \"\"\"\n",
    "        # è·å–è¿‡å» 90 å¤©æ•°æ®ä»¥è®¡ç®— MA60\n",
    "        df = self.daq.fetch_historical_kline(symbol, period='daily', start_date='20251001')\n",
    "        \n",
    "        if df.empty or len(df) < 60:\n",
    "            return \"Unknown (No Data)\", 0.0\n",
    "\n",
    "        # è®¡ç®—å‡çº¿\n",
    "        ma20 = df['close'].rolling(window=20).mean().iloc[-1]\n",
    "        ma60 = df['close'].rolling(window=60).mean().iloc[-1]\n",
    "        \n",
    "        # 1. è®¡ç®—ä¹–ç¦»ç‡ (Bias Ratio)\n",
    "        # è¡¡é‡å½“å‰ä»·æ ¼åç¦» 60 æ—¥å‡çº¿çš„ç¨‹åº¦\n",
    "        bias_60 = (current_price - ma60) / ma60 * 100\n",
    "        \n",
    "        # 2. åˆ¤æ–­çŠ¶æ€\n",
    "        if bias_60 > 30:\n",
    "            status = \"ğŸ”´ æåº¦è¿‡çƒ­ (ä¸¥é‡é€æ”¯ï¼Œåšç©º/å‡ä»“åŒºåŸŸ)\"\n",
    "        elif bias_60 > 15:\n",
    "            status = \"ğŸŸ  åé«˜ (ä¸è¦è¿½é«˜ï¼Œç­‰å¾…å›è°ƒ)\"\n",
    "        elif 0 < bias_60 <= 15:\n",
    "            status = \"ğŸŸ¢ è¶‹åŠ¿å¥åº· (æŒè‚¡/é€¢ä½å¸çº³)\"\n",
    "        elif -10 < bias_60 <= 0:\n",
    "            status = \"ğŸ”µ å›è°ƒæ”¯æ’‘ä½ (é»„é‡‘ä¹°ç‚¹)\"\n",
    "        else:\n",
    "            status = \"âšª è¶…è·Œ (å¯èƒ½æ˜¯åŸºæœ¬é¢æ¶åŒ–)\"\n",
    "            \n",
    "        return status, bias_60, ma20, ma60\n",
    "# ==========================================\n",
    "# ä¿®æ­£åçš„ Main Logic\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    db = StorageEngine()\n",
    "    daq = DataEngine()\n",
    "    \n",
    "    # è·å–ä»Šå¤©æ—¥æœŸ\n",
    "    today_str = datetime.now().strftime('%Y-%m-%d')\n",
    "    print(f\"[System] Current Date: {today_str}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Step 1: å¸‚åœºè¡Œæƒ…ç¼“å­˜æ£€æŸ¥\n",
    "    # ---------------------------------------------------------\n",
    "    latest_market_date = db.get_latest_date('market_snapshot', 'fetch_date')\n",
    "    print(f\"[Debug] DB Market Date: {latest_market_date}\")\n",
    "\n",
    "    if latest_market_date == today_str:\n",
    "        print(f\"[Cache] Today's market snapshot found. Loading...\")\n",
    "        market_data = db.load_from_sql('market_snapshot')\n",
    "    else:\n",
    "        # åªæœ‰æ—¥æœŸä¸åŒ¹é…æ—¶æ‰ä¼šæ‰“å°è¿™ä¸¤è¡Œ\n",
    "        print(f\"[DAQ] Today's snapshot not found. Fetching from API...\")\n",
    "        market_data = daq.fetch_market_snapshot()\n",
    "        market_data['fetch_date'] = today_str # æ³¨å…¥æ—¥æœŸæ ‡ç­¾\n",
    "        db.save_to_sql(market_data, 'market_snapshot')\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Step 2: æ·±åº¦è´¢åŠ¡æ•°æ®ç¼“å­˜æ£€æŸ¥ (è¿™æ˜¯æœ€è€—æ—¶çš„éƒ¨åˆ†)\n",
    "    # ---------------------------------------------------------\n",
    "    # æ£€æŸ¥ã€å…¨é‡åˆ†æè¡¨ã€‘ä»Šå¤©æ˜¯å¦å·²ç»ç”Ÿæˆè¿‡\n",
    "    latest_full_date = db.get_latest_date('full_analysis_table', 'fetch_date')\n",
    "    print(f\"[Debug] DB Full Analysis Date: {latest_full_date}\")\n",
    "\n",
    "    if latest_full_date == today_str:\n",
    "        print(f\"[Cache] Today's deep analysis found. Loading directly...\")\n",
    "        full_data = db.load_from_sql('full_analysis_table')\n",
    "    else:\n",
    "        # åªæœ‰åœ¨æ²¡æœ‰ç¼“å­˜æ—¶ï¼Œæ‰æ‰§è¡Œè€—æ—¶çš„ API å¾ªç¯æŠ“å–\n",
    "        print(f\"[Trigger] No cache for today. Starting Level 1 Trigger...\")\n",
    "        \n",
    "        # ç²—ç­›å€™é€‰å•\n",
    "        candidates = market_data[\n",
    "            (market_data['pe_ttm'] < 50) & \n",
    "            (market_data['market_cap'] > 50_0000_0000)\n",
    "        ]\n",
    "        # target_symbols = candidates['symbol'].tolist()[:2] \n",
    "        target_symbols = candidates['symbol'].tolist()\n",
    "        # æ‰§è¡Œæ˜‚è´µçš„æŠ“å–æ“ä½œ\n",
    "        finance_data = daq.fetch_detailed_financials(target_symbols)\n",
    "        \n",
    "        if not finance_data.empty:\n",
    "            full_data = pd.merge(candidates, finance_data, on='symbol', how='inner')\n",
    "            full_data['fetch_date'] = today_str # æ³¨å…¥æ—¥æœŸæ ‡ç­¾\n",
    "            db.save_to_sql(full_data, 'full_analysis_table')\n",
    "            print(f\"[Storage] Deep analysis table cached for {today_str}\")\n",
    "        else:\n",
    "            full_data = pd.DataFrame()\n",
    "            print(\"[Error] Failed to fetch financial data.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Step 3: æ‰§è¡Œæœ€ç»ˆåˆ†æ\n",
    "    # ---------------------------------------------------------\n",
    "    # ... (å‰é¢çš„ Step 1, 2, 3 ä¸å˜) ...\n",
    "    \n",
    "    if not full_data.empty:\n",
    "        # æ‰“å°ä¸€ä¸‹è¯Šæ–­ä¿¡æ¯\n",
    "        # print(\"\\n[Diagnostic] åŸå§‹æ•°æ®æ¦‚è§ˆ:\")\n",
    "        # print(full_data[['symbol', 'pe_ttm', 'roe', 'net_profit_growth']].describe())\n",
    "\n",
    "        analyzer = StrategyEngine(full_data)\n",
    "\n",
    "        # 1. è¿è¡Œå‡è¡¡å½’ä¸€åŒ–æ‰“åˆ†\n",
    "        res_score = analyzer.apply_ranking(top_n=50)\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"ğŸ“Š ç­–ç•¥ A: å‡è¡¡æ‰“åˆ† Top 10 (Normalized)\")\n",
    "        print(\"=\"*60)\n",
    "        cols_score = ['symbol', 'name', 'price', 'total_score', 'pe_ttm', 'roe', 'net_profit_growth']\n",
    "        print(res_score[cols_score].to_string(index=False))\n",
    "\n",
    "        # 2. è¿è¡Œ GARP ç­–ç•¥\n",
    "        res_garp = analyzer.select_garp(top_n=5)\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(f\"ğŸš€ ç­–ç•¥ B: GARP æˆé•¿ (PEG < 1)\")\n",
    "        print(\"-\" * 60)\n",
    "        if not res_garp.empty:\n",
    "            print(res_garp[['symbol', 'name','price', 'peg', 'pe_ttm', 'net_profit_growth']].to_string(index=False))\n",
    "        else:\n",
    "            print(\"æ— ç¬¦åˆ GARP æ ‡å‡†çš„æ ‡çš„\")\n",
    "\n",
    "        # 3. è¿è¡Œé«˜è´¨é‡æŠ¤åŸæ²³ç­–ç•¥\n",
    "        res_quality = analyzer.select_high_quality(top_n=5)\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(f\"ğŸ° ç­–ç•¥ C: æŠ¤åŸæ²³ (é«˜ ROE + é«˜æ¯›åˆ©)\")\n",
    "        print(\"-\" * 60)\n",
    "        if not res_quality.empty:\n",
    "            print(res_quality[['symbol', 'name','price', 'roe', 'gross_margin', 'debt_ratio']].to_string(index=False))\n",
    "        else:\n",
    "            print(\"æ— ç¬¦åˆæŠ¤åŸæ²³æ ‡å‡†çš„æ ‡çš„\")\n",
    "\n",
    "    db.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246dc562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System] Date: 2026-01-13\n",
      "[DAQ] Fetching Real-time Market Snapshot...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf655657e984f4c902bafcd5d8fc062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Storage] Table 'market_snapshot' saved. Rows: 5797\n",
      "[Trigger] Pre-selecting candidates...\n",
      "[DAQ] Starting Deep Reconstruction for 3200 stocks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–         | 93/3200 [00:52<31:09,  1.66it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d883f2553d04559ac9686aa622b808b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2701/3200 [15:08<04:32,  1.83it/s] "
     ]
    }
   ],
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# å¿½ç•¥ pandas çš„ FutureWarning\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# æ¨¡å— 1: StorageEngine (æ•°æ®åº“ç®¡ç†)\n",
    "# ==========================================\n",
    "class StorageEngine:\n",
    "    def __init__(self, db_path='data/stock_market.db'):\n",
    "        os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "\n",
    "    def save_to_sql(self, df, table_name, if_exists='replace'):\n",
    "        try:\n",
    "            df.to_sql(table_name, self.conn, if_exists=if_exists, index=False)\n",
    "            print(f\"[Storage] Table '{table_name}' saved. Rows: {len(df)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Storage] Error saving {table_name}: {e}\")\n",
    "\n",
    "    def load_from_sql(self, table_name):\n",
    "        try:\n",
    "            return pd.read_sql(f\"SELECT * FROM {table_name}\", self.conn)\n",
    "        except Exception as e:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def table_exists(self, table_name):\n",
    "        self.cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'\")\n",
    "        return self.cursor.fetchone() is not None\n",
    "    \n",
    "    def get_latest_date(self, table_name, date_column='fetch_date'):\n",
    "        if not self.table_exists(table_name): return None\n",
    "        try:\n",
    "            self.cursor.execute(f\"SELECT MAX({date_column}) FROM {table_name}\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except: return None\n",
    "    \n",
    "    def close(self):\n",
    "        self.conn.close()\n",
    "\n",
    "# ==========================================\n",
    "# æ¨¡å— 2: DataEngine (æ•°æ®é‡‡é›† - ç»ˆæä¿®æ­£ç‰ˆ)\n",
    "# ==========================================\n",
    "class DataEngine:\n",
    "    def __init__(self):\n",
    "        self.request_interval = 0.5 \n",
    "\n",
    "    def fetch_market_snapshot(self):\n",
    "        print(\"[DAQ] Fetching Real-time Market Snapshot...\")\n",
    "        try:\n",
    "            df_spot = ak.stock_zh_a_spot_em()\n",
    "            rename_map = {\n",
    "                'ä»£ç ': 'symbol', 'åç§°': 'name', \n",
    "                'æœ€æ–°ä»·': 'price', 'æ¶¨è·Œå¹…': 'change_pct',\n",
    "                'å¸‚ç›ˆç‡-åŠ¨æ€': 'pe_ttm', 'å¸‚å‡€ç‡': 'pb', \n",
    "                'æ€»å¸‚å€¼': 'market_cap', 'æ¢æ‰‹ç‡': 'turnover'\n",
    "            }\n",
    "            df_spot = df_spot.rename(columns=rename_map)\n",
    "            numeric_cols = ['pe_ttm', 'pb', 'market_cap', 'change_pct', 'price']\n",
    "            for col in numeric_cols:\n",
    "                if col in df_spot.columns:\n",
    "                    df_spot[col] = pd.to_numeric(df_spot[col], errors='coerce')\n",
    "            return df_spot\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Market snapshot failed: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def fetch_historical_kline(self, symbol, period='daily', start_date='20251001'):\n",
    "        \"\"\"è·å–Kçº¿æ•°æ®ç”¨äºè®¡ç®—ä¹–ç¦»ç‡\"\"\"\n",
    "        try:\n",
    "            # é€‚é… akshare æ¥å£å˜åŒ–ï¼Œå°è¯•è‡ªåŠ¨è¡¥å…¨å‰ç¼€\n",
    "            df = ak.stock_zh_a_hist(symbol=symbol, period=period, start_date=start_date, adjust=\"qfq\")\n",
    "            if df.empty: return pd.DataFrame()\n",
    "            \n",
    "            df = df.rename(columns={'æ—¥æœŸ':'date', 'å¼€ç›˜':'open', 'æ”¶ç›˜':'close', \n",
    "                                  'æœ€é«˜':'high', 'æœ€ä½':'low', 'æˆäº¤é‡':'volume'})\n",
    "            return df\n",
    "        except:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def fetch_detailed_financials(self, symbol_list):\n",
    "        print(f\"[DAQ] Starting Deep Reconstruction for {len(symbol_list)} stocks...\")\n",
    "        financial_data = []\n",
    "        \n",
    "        for symbol in tqdm(symbol_list):\n",
    "            try:\n",
    "                df = None\n",
    "                source = 'em'\n",
    "                \n",
    "                # 1. å°è¯• EM æ¥å£\n",
    "                try:\n",
    "                    df = ak.stock_financial_analysis_indicator(symbol=symbol)\n",
    "                    if df is None or df.empty: raise ValueError\n",
    "                except:\n",
    "                    # 2. å°è¯• THS æ¥å£\n",
    "                    try:\n",
    "                        source = 'ths'\n",
    "                        df = ak.stock_financial_abstract_ths(symbol=symbol, indicator=\"æŒ‰æŠ¥å‘ŠæœŸ\")\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "                if df is None or df.empty: continue\n",
    "\n",
    "                # --- å…³é”®ä¿®æ­£ 1: å¼ºåˆ¶æŒ‰æ—¥æœŸé™åºæ’åˆ— (é˜²æ­¢å–åˆ°2011å¹´æ•°æ®) ---\n",
    "                date_col = None\n",
    "                for col in df.columns:\n",
    "                    if 'æ—¥æœŸ' in str(col) or 'æŠ¥å‘ŠæœŸ' in str(col):\n",
    "                        date_col = col\n",
    "                        break\n",
    "                \n",
    "                if date_col:\n",
    "                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "                    df = df.sort_values(by=date_col, ascending=False)\n",
    "                \n",
    "                latest = df.iloc[0] # è·å–æœ€æ–°ä¸€è¡Œ\n",
    "\n",
    "                # --- å…³é”®ä¿®æ­£ 2: æ¨¡ç³ŠåŒ¹é… (é˜²æ­¢åˆ—åä¸åŒ¹é…è¿”å›0) ---\n",
    "                def get_fuzzy(keywords_list):\n",
    "                    for col_name in latest.index:\n",
    "                        if any(k in str(col_name) for k in keywords_list):\n",
    "                            raw_val = latest[col_name]\n",
    "                            if isinstance(raw_val, bool): return 0.0 # è¿‡æ»¤å¸ƒå°”å€¼\n",
    "                            val_str = str(raw_val).replace('%', '').replace(',', '').replace('ä¸‡', '').replace('äº¿', '')\n",
    "                            try:\n",
    "                                return float(val_str)\n",
    "                            except:\n",
    "                                return 0.0\n",
    "                    return 0.0\n",
    "\n",
    "                data_point = {'symbol': symbol}\n",
    "                data_point['roe'] = get_fuzzy(['å‡€èµ„äº§æ”¶ç›Šç‡', 'ROE'])\n",
    "                data_point['gross_margin'] = get_fuzzy(['æ¯›åˆ©ç‡', 'é”€å”®æ¯›åˆ©'])\n",
    "                data_point['net_profit_growth'] = get_fuzzy(['å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿', 'å‡€åˆ©æ¶¦å¢é•¿', 'å½’å±å‡€åˆ©æ¶¦åŒæ¯”'])\n",
    "                data_point['debt_ratio'] = get_fuzzy(['èµ„äº§è´Ÿå€ºç‡', 'è´Ÿå€ºåˆè®¡'])\n",
    "                data_point['eps'] = get_fuzzy(['åŸºæœ¬æ¯è‚¡æ”¶ç›Š', 'æ¯è‚¡æ”¶ç›Š'])\n",
    "                data_point['ocf_per_share'] = get_fuzzy(['æ¯è‚¡ç»è¥æ´»åŠ¨', 'æ¯è‚¡ç»è¥ç°é‡‘', 'ç»è¥å‡€ç°é‡‘æµ/è‚¡'])\n",
    "                \n",
    "                eps = data_point['eps']\n",
    "                data_point['cash_to_profit_ratio'] = (data_point['ocf_per_share'] / eps) if eps != 0 else 0\n",
    "                \n",
    "                financial_data.append(data_point)\n",
    "                time.sleep(0.3 if source == 'em' else 0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "                    \n",
    "        return pd.DataFrame(financial_data)\n",
    "\n",
    "# ==========================================\n",
    "# æ¨¡å— 3: StrategyEngine (é€‰è‚¡ç­–ç•¥)\n",
    "# ==========================================\n",
    "class StrategyEngine:\n",
    "    def __init__(self, data, exclude_star=True):\n",
    "        \"\"\"\n",
    "        :param exclude_star: True åˆ™è‡ªåŠ¨å‰”é™¤ç§‘åˆ›æ¿(688)å’Œåˆ›ä¸šæ¿(300)\n",
    "        \"\"\"\n",
    "        self.data = data.fillna(0)\n",
    "        \n",
    "        if exclude_star:\n",
    "            # å¸‚åœºå‡†å…¥è¿‡æ»¤\n",
    "            initial_count = len(self.data)\n",
    "            # å‰”é™¤ 688 å’Œ 300 å¼€å¤´çš„è‚¡ç¥¨\n",
    "            self.data = self.data[\n",
    "                ~self.data['symbol'].astype(str).str.startswith(('688', '30', '92', '8', '4'))\n",
    "            ]\n",
    "            removed_count = initial_count - len(self.data)\n",
    "            print(f\"[Init] Market Filter: Excluded {removed_count} STAR/ChiNext stocks.\")\n",
    "\n",
    "    def _normalize(self, series, ascending=True):\n",
    "        if series.empty: return series\n",
    "        upper = series.quantile(0.95)\n",
    "        lower = series.quantile(0.05)\n",
    "        if upper == lower: return series * 0\n",
    "        series_clipped = series.clip(lower, upper)\n",
    "\n",
    "        if ascending:\n",
    "            score = (series_clipped - lower) / (upper - lower) * 100\n",
    "        else:\n",
    "            score = (upper - series_clipped) / (upper - lower) * 100\n",
    "        return score.fillna(0)\n",
    "\n",
    "    def apply_ranking(self, top_n=20):\n",
    "        \"\"\"ç­–ç•¥ A: å‡è¡¡æ‰“åˆ†\"\"\"\n",
    "        print(\"[Analysis] Calculating Balanced Scores...\")\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # åŸºç¡€è¿‡æ»¤\n",
    "        mask = (df['pe_ttm'] > 0) & (df['pe_ttm'] < 80) & (df['market_cap'] > 20_0000_0000)\n",
    "        df = df[mask].copy()\n",
    "        if df.empty: return pd.DataFrame()\n",
    "\n",
    "        # å½’ä¸€åŒ–\n",
    "        df['score_val'] = self._normalize(df['pe_ttm'], ascending=False)\n",
    "        df['score_roe'] = self._normalize(df['roe'], ascending=True)\n",
    "        df['score_growth'] = self._normalize(df['net_profit_growth'], ascending=True)\n",
    "        df['score_cash'] = self._normalize(df['cash_to_profit_ratio'], ascending=True)\n",
    "\n",
    "        # ç»¼åˆæ‰“åˆ†\n",
    "        df['total_score'] = (\n",
    "            df['score_roe'] * 0.4 +\n",
    "            df['score_growth'] * 0.3 +\n",
    "            df['score_val'] * 0.2 +\n",
    "            df['score_cash'] * 0.1\n",
    "        )\n",
    "        if top_n > 0:\n",
    "            return df.sort_values(by='total_score', ascending=False).head(top_n)\n",
    "        return df.sort_values(by='total_score', ascending=False)\n",
    "\n",
    "    def select_garp(self, top_n=10):\n",
    "        \"\"\"ç­–ç•¥ B: GARP æˆé•¿\"\"\"\n",
    "        print(\"[Analysis] Applying GARP Strategy...\")\n",
    "        df = self.data.copy()\n",
    "        mask = (df['pe_ttm'] > 0) & (df['net_profit_growth'] > 0)\n",
    "        df = df[mask].copy()\n",
    "        df['peg'] = df['pe_ttm'] / df['net_profit_growth']\n",
    "        \n",
    "        cuts = (\n",
    "            (df['peg'] < 1.0) & (df['peg'] > 0.1) & \n",
    "            (df['roe'] > 12) & (df['net_profit_growth'] > 15)\n",
    "        )\n",
    "        if top_n > 0:\n",
    "            return df[cuts].sort_values(by='peg', ascending=True).head(top_n)\n",
    "        return df[cuts].sort_values(by='peg', ascending=True)\n",
    "    \n",
    "    def select_high_quality(self, top_n=10):\n",
    "        \"\"\"ç­–ç•¥ C: æŠ¤åŸæ²³\"\"\"\n",
    "        print(\"[Analysis] Applying High Quality Strategy...\")\n",
    "        df = self.data.copy()\n",
    "        cuts = (\n",
    "            (df['roe'] > 15) & (df['gross_margin'] > 30) & \n",
    "            (df['debt_ratio'] < 60) & (df['cash_to_profit_ratio'] > 0.8)\n",
    "        )\n",
    "        if top_n > 0:\n",
    "            return df[cuts].sort_values(by='roe', ascending=False).head(top_n)\n",
    "        return df[cuts].sort_values(by='roe', ascending=False)\n",
    "    \n",
    "\n",
    "# ==========================================\n",
    "# æ¨¡å— 4: RiskManager (é£æ§ä¸æ‹©æ—¶)\n",
    "# ==========================================\n",
    "class RiskManager:\n",
    "    def __init__(self, daq_engine: DataEngine):\n",
    "        self.daq = daq_engine\n",
    "\n",
    "    def assess_risk(self, symbol, current_price):\n",
    "        \"\"\"\n",
    "        è®¡ç®—ä¹–ç¦»ç‡ï¼Œåˆ¤æ–­æ˜¯å¦è¿‡çƒ­\n",
    "        \"\"\"\n",
    "        # è·å– K çº¿ (è¿‡å» 4 ä¸ªæœˆ)\n",
    "        df = self.daq.fetch_historical_kline(symbol, period='daily', start_date='20250601')\n",
    "        \n",
    "        if df.empty or len(df) < 60:\n",
    "            return \"âšª æ•°æ®ä¸è¶³\", 0.0, 0.0\n",
    "\n",
    "        # è®¡ç®—å‡çº¿\n",
    "        ma20 = df['close'].rolling(window=20).mean().iloc[-1]\n",
    "        ma60 = df['close'].rolling(window=60).mean().iloc[-1]\n",
    "        \n",
    "        # è®¡ç®—ä¹–ç¦»ç‡ Bias (ç°ä»·åç¦»å­£çº¿çš„ç¨‹åº¦)\n",
    "        bias_60 = (current_price - ma60) / ma60 * 100\n",
    "        \n",
    "        # åˆ¤å®šçº¢ç»¿ç¯\n",
    "        if bias_60 > 30:\n",
    "            status = \"ğŸ”´ æåº¦è¿‡çƒ­ (ä¸¥é‡é€æ”¯ï¼Œå»ºè®®å›é¿)\"\n",
    "        elif bias_60 > 10:\n",
    "            status = \"ğŸŸ  åé«˜ (ä¸è¦è¿½é«˜ï¼Œç­‰å¾…å›è°ƒ)\"\n",
    "        elif 0 < bias_60 <= 10:\n",
    "            status = \"ğŸŸ¢ è¶‹åŠ¿å¥åº· (æŒè‚¡/é€¢ä½å¸çº³)\"\n",
    "        elif -10 < bias_60 <= 0:\n",
    "            status = \"ğŸ”µ å›è°ƒæ”¯æ’‘ä½ (é»„é‡‘ä¹°ç‚¹)\"\n",
    "        else:\n",
    "            status = \"âšª è¶…è·Œ/å¼±åŠ¿ (éœ€ç»“åˆåŸºæœ¬é¢)\"\n",
    "            \n",
    "        return status, bias_60, ma60\n",
    "class MoneyFlowAnalyzer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_money_flow(self, symbol):\n",
    "        \"\"\"\n",
    "        [ç»´åº¦1] è·å–ä¸ªè‚¡èµ„é‡‘æµå‘ (è®¡ç®—å¤§å•å‡€æµå…¥å æ¯”)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # akshare æ¥å£ï¼šä¸ªè‚¡èµ„é‡‘æµå‘\n",
    "            # æ³¨æ„ï¼šè¿™ä¸ªæ¥å£è¿”å›çš„æ˜¯å†å²æ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦å–æœ€è¿‘çš„ä¸€å¤©\n",
    "            df = ak.stock_individual_fund_flow(stock=symbol, market=\"sh\" if symbol.startswith('6') else \"sz\")\n",
    "            if df.empty: return 0.0, \"æ— æ•°æ®\"\n",
    "            \n",
    "            # è¿™é‡Œçš„åˆ—åé€šå¸¸åŒ…æ‹¬ï¼šæ—¥æœŸ, ä¸»åŠ›å‡€æµå…¥-å‡€é¢, ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”...\n",
    "            # æˆ‘ä»¬æŒ‰æ—¥æœŸé™åº\n",
    "            df = df.sort_values(by='æ—¥æœŸ', ascending=False)\n",
    "            latest = df.iloc[0]\n",
    "            \n",
    "            # è·å–ä¸»åŠ›å‡€å æ¯” (Net Flow Ratio)\n",
    "            # å¦‚æœ > 0 è¯´æ˜ä¸»åŠ›åœ¨ä¹°ï¼Œ> 10% è¯´æ˜ä¸»åŠ›åœ¨å¤§ä¹°\n",
    "            net_ratio = float(latest['ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”'])\n",
    "            \n",
    "            if net_ratio > 10:\n",
    "                status = \"ğŸ”¥ ä¸»åŠ›æŠ¢ç­¹\"\n",
    "            elif net_ratio > 0:\n",
    "                status = \"ğŸ”´ ä¸»åŠ›å°ä¹°\"\n",
    "            elif net_ratio > -10:\n",
    "                status = \"ğŸŸ¢ ä¸»åŠ›å°å–\"\n",
    "            else:\n",
    "                status = \"ğŸ§Š ä¸»åŠ›å‡ºé€ƒ\"\n",
    "                \n",
    "            return net_ratio, status\n",
    "        except:\n",
    "            return 0.0, \"æ•°æ®ç¼ºå¤±\"\n",
    "\n",
    "    def check_dragon_tiger(self, symbol, date_str):\n",
    "        \"\"\"\n",
    "        [ç»´åº¦2] æ£€æŸ¥æœ€è¿‘æ˜¯å¦ä¸Šè¿‡é¾™è™æ¦œ (LHB)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # è·å–æŒ‡å®šæ—¥æœŸçš„é¾™è™æ¦œè¯¦æƒ…\n",
    "            # è¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒé‡çš„æŸ¥è¯¢ï¼Œå®é™…ç­–ç•¥ä¸­å»ºè®®åªæŸ¥ Top è‚¡\n",
    "            lhb_df = ak.stock_lhb_detail_em(start_date=date_str, end_date=date_str)\n",
    "            \n",
    "            if symbol in lhb_df['ä»£ç '].values:\n",
    "                # å¦‚æœä¸Šæ¦œï¼Œè¿›ä¸€æ­¥åˆ†ææ˜¯è°åœ¨ä¹°\n",
    "                target_row = lhb_df[lhb_df['ä»£ç '] == symbol].iloc[0]\n",
    "                \n",
    "                buy_amt = float(target_row['ä¹°å…¥æ€»è®¡'])\n",
    "                sell_amt = float(target_row['å–å‡ºæ€»è®¡'])\n",
    "                net_buy = buy_amt - sell_amt\n",
    "                \n",
    "                return True, net_buy\n",
    "            return False, 0.0\n",
    "        except:\n",
    "            return False, 0.0\n",
    "# ==========================================\n",
    "# è¾…åŠ©å‡½æ•°: æ‰“å°æ¼‚äº®çš„æŠ¥è¡¨\n",
    "# ==========================================\n",
    "\n",
    "def print_report(df: pd.DataFrame, risk_mgr: RiskManager, flow_analyzer: MoneyFlowAnalyzer, title: str):\n",
    "    if df.empty:\n",
    "        print(f\"\\n--- {title} æ— åŒ¹é…æ ‡çš„ ---\")\n",
    "        return\n",
    "\n",
    "    # 1. æ•°æ®å¢å¼ºï¼šå…ˆè®¡ç®—æ‰€æœ‰æŒ‡æ ‡ï¼Œå­˜å…¥ä¸´æ—¶ DataFrame ä»¥ä¾¿æ’åº\n",
    "    report_list = []\n",
    "    \n",
    "    print(f\"\\n[Report] Analyzing {len(df)} candidates for {title}...\")\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        symbol = row['symbol']\n",
    "        price = row.get('price', 0)\n",
    "        \n",
    "        # æŠ€æœ¯é¢\n",
    "        status_tech, bias, ma60 = risk_mgr.assess_risk(symbol, price)\n",
    "        # èµ„é‡‘é¢\n",
    "        mf_ratio, mf_status = flow_analyzer.get_money_flow(symbol)\n",
    "        \n",
    "        # --- æ ¸å¿ƒå†³ç­–é€»è¾‘ (Decision Matrix) ---\n",
    "        # è¯„åˆ†ç³»ç»Ÿï¼šèµ„é‡‘æµæƒé‡é«˜ï¼Œä½ç½®æƒé‡æ¬¡ä¹‹\n",
    "        \n",
    "        signal = \"âšª è§‚æœ›\"\n",
    "        rank_val = 0 # ç”¨äºæ’åº\n",
    "        \n",
    "        if mf_ratio > 5: # ä¸»åŠ›åœ¨å¤§ä¹°\n",
    "            if bias < 0:\n",
    "                signal = \"ğŸ’ åº•éƒ¨å…±æŒ¯ (æå“)\"\n",
    "                rank_val = 100\n",
    "            elif 0 <= bias < 15:\n",
    "                signal = \"ğŸš€ è¶‹åŠ¿åŠ é€Ÿ (è¿›æ”»)\"\n",
    "                rank_val = 90\n",
    "            else:\n",
    "                signal = \"âš  èµ„é‡‘è¯±å¤š (è¿‡çƒ­)\"\n",
    "                rank_val = 40\n",
    "        elif mf_ratio > 0: # ä¸»åŠ›å°ä¹°\n",
    "            if bias < 0:\n",
    "                signal = \"ğŸ’° ä½å¸æ½œä¼\"\n",
    "                rank_val = 80\n",
    "            elif 0 <= bias < 15:\n",
    "                signal = \"âœ… é¡ºåŠ¿æŒè‚¡\"\n",
    "                rank_val = 70\n",
    "            else:\n",
    "                signal = \"ğŸŸ  åˆ†æ‰¹æ­¢ç›ˆ\"\n",
    "                rank_val = 50\n",
    "        else: # ä¸»åŠ›åœ¨å–\n",
    "            if bias > 20:\n",
    "                signal = \"â˜  é¡¶éƒ¨èƒŒç¦» (å¿«è·‘)\"\n",
    "                rank_val = -10\n",
    "            else:\n",
    "                signal = \"ğŸ§Š é˜´è·Œé£é™©\"\n",
    "                rank_val = 10\n",
    "                \n",
    "        report_list.append({\n",
    "            'symbol': symbol,\n",
    "            'name': row['name'],\n",
    "            'price': price,\n",
    "            'pe': row['pe_ttm'],\n",
    "            'roe': row['roe'],\n",
    "            'bias': bias,\n",
    "            'ma60': ma60,\n",
    "            'mf_ratio': mf_ratio,\n",
    "            'signal': signal,\n",
    "            'rank': rank_val\n",
    "        })\n",
    "        \n",
    "    # 2. æ’åºï¼šæŒ‰ rank (æ¨èåº¦) é™åºï¼Œå…¶æ¬¡æŒ‰ èµ„é‡‘æµ é™åº\n",
    "    report_df = pd.DataFrame(report_list)\n",
    "    report_df = report_df.sort_values(by=['rank', 'mf_ratio'], ascending=[False, False])\n",
    "\n",
    "    # 3. æ‰“å°æ¼‚äº®æŠ¥è¡¨\n",
    "    print(\"\\n\" + \"=\"*115)\n",
    "    print(f\"ğŸ“Š {title} (å·²æŒ‰æ¨èåº¦æ’åº)\")\n",
    "    print(\"=\"*115)\n",
    "    \n",
    "    # åŠ¨æ€è¡¨å¤´\n",
    "    headers = f\"{'ä»£ç ':<8} {'åç§°':<8} {'ç°ä»·':<8} {'PE':<8} {'ROE':<6} {'ä¹–ç¦»ç‡%':<8} {'MA60':<8} {'ä¸»åŠ›å‡€æµ%':<10} {'AIå†³ç­–å»ºè®®'}\"\n",
    "    print(headers)\n",
    "    print(\"-\" * 115)\n",
    "\n",
    "    for _, row in report_df.iterrows():\n",
    "        # é¢œè‰²æ ‡è®° (ä»…åœ¨æ”¯æŒANSIçš„ç»ˆç«¯æœ‰æ•ˆï¼Œæ™®é€šç»ˆç«¯ä¼šæ˜¾ç¤ºä¸ºæ™®é€šæ–‡æœ¬)\n",
    "        # ç¨å¾®è°ƒæ•´ä¸€ä¸‹æ ¼å¼ï¼Œè®©å®ƒæ›´åƒä¸“ä¸šè½¯ä»¶\n",
    "        print(f\"{row['symbol']:<8} {row['name']:<8} {row['price']:<8.2f} {row['pe']:<8.1f} {row['roe']:<6.1f} {row['bias']:<8.1f} {row['ma60']:<8.2f} {row['mf_ratio']:<10.2f} {row['signal']}\")\n",
    "    \n",
    "    print(\"=\"*115)\n",
    "\n",
    "# ==========================================\n",
    "# Main Logic\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    db = StorageEngine()\n",
    "    daq = DataEngine()\n",
    "    \n",
    "    today_str = datetime.now().strftime('%Y-%m-%d')\n",
    "    print(f\"[System] Date: {today_str}\")\n",
    "\n",
    "    # 1. å¸‚åœºè¡Œæƒ… (Level 1)\n",
    "    latest_market_date = db.get_latest_date('market_snapshot', 'fetch_date')\n",
    "    if latest_market_date == today_str:\n",
    "        print(f\"[Cache] Loading market snapshot...\")\n",
    "        market_data = db.load_from_sql('market_snapshot')\n",
    "    else:\n",
    "        market_data = daq.fetch_market_snapshot()\n",
    "        market_data['fetch_date'] = today_str\n",
    "        db.save_to_sql(market_data, 'market_snapshot')\n",
    "\n",
    "    # 2. è´¢åŠ¡æ•°æ® (Level 3)\n",
    "    latest_full_date = db.get_latest_date('full_analysis_table', 'fetch_date')\n",
    "    \n",
    "    if latest_full_date == today_str:\n",
    "        print(f\"[Cache] Loading deep analysis data...\")\n",
    "        full_data = db.load_from_sql('full_analysis_table')\n",
    "    else:\n",
    "        print(f\"[Trigger] Pre-selecting candidates...\")\n",
    "        # ç²—ç­›ï¼šPE < 60 ä¸”å¸‚å€¼ > 30äº¿ (ç¨å¾®æ”¾å®½ä¸€ç‚¹ï¼Œé¿å…ç­›ç©º)\n",
    "        candidates = market_data[\n",
    "            (market_data['pe_ttm'] < 60) & \n",
    "            (market_data['market_cap'] > 30_0000_0000)\n",
    "        ]\n",
    "    \n",
    "        target_symbols = candidates['symbol'].tolist()\n",
    "        \n",
    "        finance_data = daq.fetch_detailed_financials(target_symbols)\n",
    "        \n",
    "        if not finance_data.empty:\n",
    "            full_data = pd.merge(candidates, finance_data, on='symbol', how='inner')\n",
    "            full_data['fetch_date'] = today_str\n",
    "            db.save_to_sql(full_data, 'full_analysis_table')\n",
    "            print(f\"[Storage] Saved {len(full_data)} rows.\")\n",
    "        else:\n",
    "            full_data = pd.DataFrame()\n",
    "            print(\"[Error] Financial data fetch failed.\")\n",
    "\n",
    "    # 3. ç­–ç•¥åˆ†æä¸é£æ§ (Analysis & Risk)\n",
    "    if not full_data.empty:\n",
    "        # åˆå§‹åŒ–ç­–ç•¥å¼•æ“ (exclude_star=True å‰”é™¤ç§‘åˆ›/åˆ›ä¸šæ¿)\n",
    "        analyzer = StrategyEngine(full_data, exclude_star=True)\n",
    "        # åˆå§‹åŒ–é£æ§å¼•æ“\n",
    "        risk_mgr = RiskManager(daq)\n",
    "        flow_mgr = MoneyFlowAnalyzer()\n",
    "        # è¿è¡Œç­–ç•¥ A: å‡è¡¡æ‰“åˆ†\n",
    "        res_score = analyzer.apply_ranking(top_n=0)\n",
    "        print_report(res_score, risk_mgr,flow_mgr, \"ç­–ç•¥ A: å‡è¡¡ä¼˜é€‰ (ç»¼åˆè¯„åˆ†)\")\n",
    "\n",
    "        # è¿è¡Œç­–ç•¥ B: GARP æˆé•¿\n",
    "        res_garp = analyzer.select_garp(top_n=200)\n",
    "        print_report(res_garp, risk_mgr,flow_mgr, \"ç­–ç•¥ B: GARP æˆé•¿ (ä½PEG)\")\n",
    "\n",
    "        # è¿è¡Œç­–ç•¥ C: æŠ¤åŸæ²³\n",
    "        res_quality = analyzer.select_high_quality(top_n=200)\n",
    "        print_report(res_quality, risk_mgr,flow_mgr, \"ç­–ç•¥ C: ä¼˜è´¨æŠ¤åŸæ²³ (é«˜ROE)\")\n",
    "\n",
    "    db.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
